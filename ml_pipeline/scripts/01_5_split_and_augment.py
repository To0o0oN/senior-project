import os
import shutil
import librosa
import soundfile as sf
import numpy as np
from sklearn.model_selection import train_test_split
from tqdm import tqdm

# --- 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå ---
INPUT_DIR = "ml_pipeline/data/03_labeled"
OUTPUT_DIR = "ml_pipeline/data/dataset_audio"
TARGET_SR = 22050 # ‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô

def add_noise(data, noise_factor=0.005):
    noise = np.random.randn(len(data))
    return data + noise_factor * noise

def pitch_shift(data, sr, n_steps):
    return librosa.effects.pitch_shift(y=data, sr=sr, n_steps=n_steps)

def time_stretch(data, rate):
    return librosa.effects.time_stretch(y=data, rate=rate)

def process_and_save(file_path, save_dir, filename, is_train=False):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ã‡∏ü (‡∏ó‡∏≥ Augment ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô is_train=True)"""
    y, sr = librosa.load(file_path, sr=TARGET_SR)
    
    # ‡πÄ‡∏ã‡∏ü‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÄ‡∏™‡∏°‡∏≠ ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà Train, Val ‡∏´‡∏£‡∏∑‡∏≠ Test
    sf.write(os.path.join(save_dir, f"{filename}_ori.wav"), y, sr)
    
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Train ‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏±‡πä‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏° (Augmentation)
    if is_train:
        sf.write(os.path.join(save_dir, f"{filename}_pitch.wav"), pitch_shift(y, sr, 2), sr)
        sf.write(os.path.join(save_dir, f"{filename}_stretch.wav"), time_stretch(y, 1.1), sr)
        sf.write(os.path.join(save_dir, f"{filename}_noise.wav"), add_noise(y), sr)

def main():
    print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° 80:10:10 ‡πÅ‡∏•‡∏∞ Augment ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    classes = ["0_noise", "1_singing"]
    
    for cls in classes:
        in_class_dir = os.path.join(INPUT_DIR, cls)
        if not os.path.exists(in_class_dir):
            continue
            
        files = [f for f in os.listdir(in_class_dir) if f.endswith('.wav')]
        
        # 1. ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Train (80%) ‡πÅ‡∏•‡∏∞ Temp (20%)
        train_files, temp_files = train_test_split(files, test_size=0.2, random_state=42)
        # 2. ‡πÅ‡∏ö‡πà‡∏á Temp (20%) ‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô Val (10%) ‡πÅ‡∏•‡∏∞ Test (10%)
        val_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=42)
        
        splits = {
            'train': (train_files, True),  # True = ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡∏ó‡∏≥ Augment
            'val': (val_files, False),     # False = ‡∏´‡πâ‡∏≤‡∏°‡∏ó‡∏≥ Augment (‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö)
            'test': (test_files, False)    # False = ‡∏´‡πâ‡∏≤‡∏°‡∏ó‡∏≥ Augment (‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö)
        }
        
        for split_name, (split_files, do_augment) in splits.items():
            out_dir = os.path.join(OUTPUT_DIR, split_name, cls)
            os.makedirs(out_dir, exist_ok=True)
            
            desc = f"‡∏õ‡∏±‡πä‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {cls} ({split_name})" if do_augment else f"‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å {cls} ({split_name})"
            for file in tqdm(split_files, desc=desc, unit="file"):
                file_path = os.path.join(in_class_dir, file)
                filename = os.path.splitext(file)[0]
                process_and_save(file_path, out_dir, filename, is_train=do_augment)
                
    print(f"\nüéâ ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ Augment ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! ‡πÄ‡∏ä‡πá‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà: {OUTPUT_DIR}")

if __name__ == "__main__":
    main()